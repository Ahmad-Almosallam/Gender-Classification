{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-RCz9fNv5w"
      },
      "source": [
        "# 1- Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRAqsZMlYhT"
      },
      "source": [
        "import IPython.display as ipd\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLXZr6qwBWa0"
      },
      "source": [
        "import soundfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poEC9iJtN7Qo"
      },
      "source": [
        "# 2- Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB513L8ImDOr"
      },
      "source": [
        "# Loading the extracted features data\n",
        "features_label = np.load('features_label.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV3dpw05pelH"
      },
      "source": [
        "# We create an empty list where we will concatenate all the features into one long feature\n",
        "features = []\n",
        "for i in range(0, len(features_label)):\n",
        "    features.append(np.concatenate((features_label[i][0], features_label[i][1], \n",
        "                features_label[i][2], features_label[i][3],\n",
        "                features_label[i][4]), axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI6hXCprpkdD"
      },
      "source": [
        "# Similarly, we create a list where we will store all the labels\n",
        "labels = []\n",
        "for i in range(0, len(features_label)):\n",
        "    labels.append(features_label[i][5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYOpZPGFqsRg"
      },
      "source": [
        "# Splitting the data to target and features\n",
        "X = np.array(features)\n",
        "y = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyjuLKIOeWV"
      },
      "source": [
        "# 3- Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fygZJXrJOd"
      },
      "source": [
        "# Scaling the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkK4CEwiuA-h",
        "outputId": "48aafbe8-3bb3-483e-bec9-aed29ece2b35"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13125, 193)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGK5p0CudGI"
      },
      "source": [
        "# Encoding the data\n",
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXYKm4JWuCiJ",
        "outputId": "fd5ca436-9db4-4b63-e850-af704b294ad9"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13125,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pMvSYDmOuCG"
      },
      "source": [
        "## Methods for predicting on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQboPVmGNmN0"
      },
      "source": [
        "def extract_features(files):\n",
        "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
        "    # Sample rate is set to 22050 by default\n",
        "    X, sample_rate = librosa.load(files, res_type='kaiser_fast') \n",
        "\n",
        "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "\n",
        "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "\n",
        "    # Computes a chromagram from a waveform or power spectrogram.\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes a mel-scaled spectrogram.\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes spectral contrast\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes the tonal centroid features (tonnetz)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    sr=sample_rate).T,axis=0)\n",
        "    \n",
        "\n",
        "    return mfccs, chroma, mel, contrast, tonnetz\n",
        "\n",
        "def predict(filename,model):\n",
        "  feat = extract_features(filename)\n",
        "  features = np.concatenate((feat[0], feat[1], feat[2], feat[3],feat[4]),axis=0)\n",
        "  c = scaler.transform([features])\n",
        "  return model.predict(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-d2eBmRqM_q",
        "outputId": "4846bced-086a-49fe-ee3a-cee0909401dc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(\"Train set -> \" , len(X_train))\n",
        "print(\"Test set -> \" , len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set ->  10500\n",
            "Test set ->  2625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMkhqdeqNroW"
      },
      "source": [
        "# 4- Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aL9uCBzO3L1"
      },
      "source": [
        "## Building SVC model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skTmzxoPva6m"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "mod = SVC()\n",
        "\n",
        "mod.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m0HgAZIwDnY"
      },
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRbN8ew1O7-z"
      },
      "source": [
        "##Building LogisticRegression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcQUWNU0M-ss"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "mod_LogisticRegression = LogisticRegression(max_iter=400)\n",
        "\n",
        "mod_LogisticRegression.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsWaZvGZUdHR"
      },
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_LogisticRegression.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_LogisticRegression.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_LogisticRegression.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1GGJHpTOst"
      },
      "source": [
        "##Building AdaBoostClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENi1oETxTSyP"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "mod_AdaBoostClassifier = AdaBoostClassifier()\n",
        "\n",
        "mod_AdaBoostClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3KrzpoTj3d"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_AdaBoostClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_AdaBoostClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_AdaBoostClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhyps05IUPzj"
      },
      "source": [
        "## Building BaggingClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0TXgetTyBm"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "mod_BaggingClassifier = BaggingClassifier()\n",
        "\n",
        "mod_BaggingClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQop04OT4Ng"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_BaggingClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_BaggingClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_BaggingClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxyPV8hTUXJu"
      },
      "source": [
        "## Building GradientBoostingClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqSrWVRiUVBC"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "mod_GradientBoostingClassifier = GradientBoostingClassifier()\n",
        "\n",
        "mod_GradientBoostingClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTF7e_SIUZYt"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_GradientBoostingClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_GradientBoostingClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_GradientBoostingClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zfPjnYuVlZW"
      },
      "source": [
        "## Building RandomForestClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur-re6cPU9DX",
        "outputId": "dfb1f65e-1ed9-40db-9697-eb9c0d8097d8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "mod_RandomForestClassifier = RandomForestClassifier()\n",
        "\n",
        "mod_RandomForestClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eg3ACU5VA2b",
        "outputId": "eb3bf490-c6fc-4946-fcc7-88044e6f4f39"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_RandomForestClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_RandomForestClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_RandomForestClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 1.0\n",
            "Accuracy Test -> 0.9900952380952381\n",
            "F1-score Train -> 1.0\n",
            "F1-score Test -> 0.9897314375987362\n",
            "Confusion Matrix Train ->\n",
            " [[5215    0]\n",
            " [   0 5285]]\n",
            "Confusion Matrix Test ->\n",
            " [[1346    9]\n",
            " [  17 1253]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiJi5SNG3fTR"
      },
      "source": [
        "# 5- Importing pickle and pick the perfect model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQm9mRSP7wLt"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(mod_RandomForestClassifier, open('randomforest_model.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}