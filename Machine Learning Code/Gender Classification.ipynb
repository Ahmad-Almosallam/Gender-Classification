{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-RCz9fNv5w"
      },
      "source": [
        "# 1- Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRAqsZMlYhT"
      },
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poEC9iJtN7Qo"
      },
      "source": [
        "# 2- Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB513L8ImDOr"
      },
      "source": [
        "# Loading the extracted features data\n",
        "features_label = np.load('features_label.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV3dpw05pelH"
      },
      "source": [
        "# We create an empty list where we will concatenate all the features into one long feature\n",
        "features = []\n",
        "for i in range(0, len(features_label)):\n",
        "    features.append(np.concatenate((features_label[i][0], features_label[i][1], \n",
        "                features_label[i][2], features_label[i][3],\n",
        "                features_label[i][4]), axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI6hXCprpkdD"
      },
      "source": [
        "# Similarly, we create a list where we will store all the labels\n",
        "labels = []\n",
        "for i in range(0, len(features_label)):\n",
        "    labels.append(features_label[i][5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYOpZPGFqsRg"
      },
      "source": [
        "# Splitting the data to target and features\n",
        "X = np.array(features)\n",
        "y = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyjuLKIOeWV"
      },
      "source": [
        "# 3- Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fygZJXrJOd"
      },
      "source": [
        "# Scaling the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkK4CEwiuA-h",
        "outputId": "d9389767-3d88-4b33-dda9-5525d128031d"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13125, 193)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGK5p0CudGI"
      },
      "source": [
        "# Encoding the data\n",
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXYKm4JWuCiJ",
        "outputId": "cb2f993d-08f6-482a-d03e-0b29970cf6bf"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13125,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pMvSYDmOuCG"
      },
      "source": [
        "## Methods for predicting on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQboPVmGNmN0"
      },
      "source": [
        "def extract_features(files):\n",
        "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
        "    # Sample rate is set to 22050 by default\n",
        "    X, sample_rate = librosa.load(files, res_type='kaiser_fast') \n",
        "\n",
        "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "\n",
        "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "\n",
        "    # Computes a chromagram from a waveform or power spectrogram.\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes a mel-scaled spectrogram.\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes spectral contrast\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "    # Computes the tonal centroid features (tonnetz)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    sr=sample_rate).T,axis=0)\n",
        "    \n",
        "\n",
        "    return mfccs, chroma, mel, contrast, tonnetz\n",
        "\n",
        "def predict(filename,model):\n",
        "  feat = extract_features(filename)\n",
        "  features = np.concatenate((feat[0], feat[1], feat[2], feat[3],feat[4]),axis=0)\n",
        "  c = scaler.transform([features])\n",
        "  return model.predict(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-d2eBmRqM_q",
        "outputId": "b0acca1f-e83e-4268-985f-9d3870cdbd01"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(\"Train set -> \" , len(X_train))\n",
        "print(\"Test set -> \" , len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set ->  10500\n",
            "Test set ->  2625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMkhqdeqNroW"
      },
      "source": [
        "# 4- Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aL9uCBzO3L1"
      },
      "source": [
        "## Building SVC model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skTmzxoPva6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058c9ee0-ac5b-4695-d721-6b7ef4a8c0f1"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "mod = SVC()\n",
        "\n",
        "mod.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m0HgAZIwDnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed86b01-d70d-47f9-b82e-75a5035a440e"
      },
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 0.9961904761904762\n",
            "Accuracy Test -> 0.9885714285714285\n",
            "F1-score Train -> 0.9962099677847261\n",
            "F1-score Test -> 0.98812351543943\n",
            "Confusion Matrix Train ->\n",
            " [[5203   12]\n",
            " [  28 5257]]\n",
            "Confusion Matrix Test ->\n",
            " [[1347    8]\n",
            " [  22 1248]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRbN8ew1O7-z"
      },
      "source": [
        "##Building LogisticRegression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcQUWNU0M-ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d6e89e-2e03-45dd-c238-096ccd1e48b9"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "mod_LogisticRegression = LogisticRegression(max_iter=400)\n",
        "\n",
        "mod_LogisticRegression.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsWaZvGZUdHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3717f4d2-f1d2-4396-e74a-f660945bfeef"
      },
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_LogisticRegression.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_LogisticRegression.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_LogisticRegression.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_LogisticRegression.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 0.987904761904762\n",
            "Accuracy Test -> 0.984\n",
            "F1-score Train -> 0.9879723458660858\n",
            "F1-score Test -> 0.9835552075176195\n",
            "Confusion Matrix Train ->\n",
            " [[5157   58]\n",
            " [  69 5216]]\n",
            "Confusion Matrix Test ->\n",
            " [[1327   28]\n",
            " [  14 1256]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1GGJHpTOst"
      },
      "source": [
        "##Building AdaBoostClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENi1oETxTSyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa22d9c-7b69-4618-8271-af0f195ac50e"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "mod_AdaBoostClassifier = AdaBoostClassifier()\n",
        "\n",
        "mod_AdaBoostClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=50, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3KrzpoTj3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a3ecb8-fd27-4f0d-ed99-37e0fb34cc6c"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_AdaBoostClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_AdaBoostClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_AdaBoostClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_AdaBoostClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 0.9902857142857143\n",
            "Accuracy Test -> 0.9805714285714285\n",
            "F1-score Train -> 0.990339079371093\n",
            "F1-score Test -> 0.9799133517132729\n",
            "Confusion Matrix Train ->\n",
            " [[5170   45]\n",
            " [  57 5228]]\n",
            "Confusion Matrix Test ->\n",
            " [[1330   25]\n",
            " [  26 1244]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhyps05IUPzj"
      },
      "source": [
        "## Building BaggingClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0TXgetTyBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd00edd-23a3-4e6c-b0b0-375ea64ae7f0"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "mod_BaggingClassifier = BaggingClassifier()\n",
        "\n",
        "mod_BaggingClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
              "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
              "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
              "                  warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQop04OT4Ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5812bac1-4d4f-43e4-b034-96456f74f954"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_BaggingClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_BaggingClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_BaggingClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_BaggingClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 0.9992380952380953\n",
            "Accuracy Test -> 0.9847619047619047\n",
            "F1-score Train -> 0.9992427110942824\n",
            "F1-score Test -> 0.9842022116903634\n",
            "Confusion Matrix Train ->\n",
            " [[5214    1]\n",
            " [   7 5278]]\n",
            "Confusion Matrix Test ->\n",
            " [[1339   16]\n",
            " [  24 1246]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxyPV8hTUXJu"
      },
      "source": [
        "## Building GradientBoostingClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqSrWVRiUVBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8c1489-3c42-44cc-e550-ed96053f0e4a"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "mod_GradientBoostingClassifier = GradientBoostingClassifier()\n",
        "\n",
        "mod_GradientBoostingClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTF7e_SIUZYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3167329-20bc-419c-bb2d-94e9d1e2a40f"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_GradientBoostingClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_GradientBoostingClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_GradientBoostingClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_GradientBoostingClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 0.9964761904761905\n",
            "Accuracy Test -> 0.9870476190476191\n",
            "F1-score Train -> 0.9964938879939353\n",
            "F1-score Test -> 0.9865824782951854\n",
            "Confusion Matrix Train ->\n",
            " [[5205   10]\n",
            " [  27 5258]]\n",
            "Confusion Matrix Test ->\n",
            " [[1341   14]\n",
            " [  20 1250]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zfPjnYuVlZW"
      },
      "source": [
        "## Building RandomForestClassifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur-re6cPU9DX",
        "outputId": "71f74815-e61c-470c-d9b8-9452e7698590"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "mod_RandomForestClassifier = RandomForestClassifier()\n",
        "\n",
        "mod_RandomForestClassifier.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eg3ACU5VA2b",
        "outputId": "c8be46e0-a070-428b-878e-512d4e544e96"
      },
      "source": [
        "print(\"Accuracy Train ->\", accuracy_score(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"Accuracy Test ->\", accuracy_score(y_test,mod_RandomForestClassifier.predict(X_test)))\n",
        "# F1-score\n",
        "print(\"F1-score Train ->\", f1_score(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"F1-score Test ->\", f1_score(y_test,mod_RandomForestClassifier.predict(X_test)))\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix Train ->\\n\", confusion_matrix(y_train,mod_RandomForestClassifier.predict(X_train)))\n",
        "print(\"Confusion Matrix Test ->\\n\", confusion_matrix(y_test,mod_RandomForestClassifier.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Train -> 1.0\n",
            "Accuracy Test -> 0.9904761904761905\n",
            "F1-score Train -> 1.0\n",
            "F1-score Test -> 0.9901146698299723\n",
            "Confusion Matrix Train ->\n",
            " [[5215    0]\n",
            " [   0 5285]]\n",
            "Confusion Matrix Test ->\n",
            " [[1348    7]\n",
            " [  18 1252]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiJi5SNG3fTR"
      },
      "source": [
        "# 5- Importing pickle and pick the perfect model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQm9mRSP7wLt"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(mod_RandomForestClassifier, open('randomforest_model.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}